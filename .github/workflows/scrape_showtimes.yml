name: Scrape Movie Showtimes

on:
  workflow_dispatch: # Allows manual triggering
  schedule:
    # Runs every day at 15:00 UTC (midnight JST next day)
    - cron: '0 15 * * *'

jobs:
  scrape_and_commit:
    runs-on: ubuntu-latest # Use a Linux runner

    steps:
      - name: Check out repository
        uses: actions/checkout@v4 # Checks out your code

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10' # Or your preferred Python version

      - name: Install Google Chrome # For Selenium
        run: |
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          google-chrome --version # Output version for logs

      # REMOVED the complex "Install ChromeDriver" step
      # webdriver-manager in Python will handle this.

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt # Ensure requirements.txt is up-to-date

      - name: Run scraper script
        # This should be the name of your main Python script that calls
        # scrape_ygc(), scrape_cinequinto_shibuya(), etc.,
        # and then writes showtimes.json
        run: python main_scraper.py

      - name: Commit and push showtimes.json
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add showtimes.json
          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to showtimes.json to commit."
          else
            git commit -m "Automated update of showtimes.json"
            git push
            echo "showtimes.json committed and pushed."
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
